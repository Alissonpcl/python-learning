{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966f0331d8fdeca4",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "This notebook was created to solve a list of Spark challenges created using [claude.ia](https://claude.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82f8728a02a33",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:51:14.485367Z",
     "start_time": "2025-07-19T17:51:14.480256Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c3617125aa444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:49:07.579113Z",
     "start_time": "2025-07-19T17:49:07.577094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required for Spark to find Python executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk@17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b5e798507c5a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:53:06.234181Z",
     "start_time": "2025-07-19T17:53:06.024027Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/19 16:28:34 WARN Utils: Your hostname, Alissons-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.19 instead (on interface en0)\n",
      "25/07/19 16:28:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/19 16:28:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"InterviewChallenges\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb31d8232b9b147",
   "metadata": {},
   "source": [
    "# Challenge 1: Basic DataFrame Operations (Beginner)\n",
    "Problem: Given a sales dataset, perform basic transformations and aggregations.\n",
    "\n",
    "Expected Skills: DataFrame creation, column transformations, aggregations, filtering, sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8edc11d4e16e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:53:11.878934Z",
     "start_time": "2025-07-19T17:53:11.463361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "sales_data = [\n",
    "    (\"John\", \"Electronics\", 1200, \"2023-01-15\"),\n",
    "    (\"Alice\", \"Clothing\", 800, \"2023-01-16\"),\n",
    "    (\"Bob\", \"Electronics\", 1500, \"2023-01-17\"),\n",
    "    (\"Alice\", \"Books\", 300, \"2023-01-18\"),\n",
    "    (\"John\", \"Clothing\", 600, \"2023-01-19\"),\n",
    "    (\"Bob\", \"Books\", 250, \"2023-01-20\")\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"salesperson\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"amount\", IntegerType(), True),\n",
    "    StructField(\"sale_date\", StringType(), True)\n",
    "])\n",
    "\n",
    "sales_df = spark.createDataFrame(sales_data, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ce027bbc24b73",
   "metadata": {},
   "source": [
    "## Convert sale_date from string to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ece14f78a0994ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:54:59.327553Z",
     "start_time": "2025-07-19T17:54:59.315420Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_df = sales_df.withColumn('sale_date', F.col('sale_date').cast('date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a53ce2df20201a",
   "metadata": {},
   "source": [
    "## Find total sales amount by each salesperson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab3a28239127485b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:56:49.419463Z",
     "start_time": "2025-07-19T17:56:49.380559Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_amount_by_person_df = sales_df.groupby('salesperson').agg(\n",
    "    F.sum(F.col('amount')).alias('total_amount')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7abbfb90c599941a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:56:57.105618Z",
     "start_time": "2025-07-19T17:56:56.522631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|salesperson|total_amount|\n",
      "+-----------+------------+\n",
      "|       John|        1800|\n",
      "|      Alice|        1100|\n",
      "|        Bob|        1750|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_amount_by_person_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9043d250bed7b",
   "metadata": {},
   "source": [
    "## Find the average sale amount by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9496e81b0dc6da27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:59:08.856801Z",
     "start_time": "2025-07-19T17:59:08.844372Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_amount_by_category_df = sales_df.groupby('category').agg(\n",
    "    F.avg(F.col('amount')).alias('avg_amount')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c42ed047eaf6e78f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T17:59:10.623676Z",
     "start_time": "2025-07-19T17:59:10.450141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|   category|avg_amount|\n",
      "+-----------+----------+\n",
      "|Electronics|    1350.0|\n",
      "|   Clothing|     700.0|\n",
      "|      Books|     275.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_amount_by_category_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359db65112ce66f2",
   "metadata": {},
   "source": [
    "## Show only sales where amount > 500, sorted by amount descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2a4a0c5361c96fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:01:06.166225Z",
     "start_time": "2025-07-19T18:01:05.990493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------+----------+\n",
      "|salesperson|   category|amount| sale_date|\n",
      "+-----------+-----------+------+----------+\n",
      "|        Bob|Electronics|  1500|2023-01-17|\n",
      "|       John|Electronics|  1200|2023-01-15|\n",
      "|      Alice|   Clothing|   800|2023-01-16|\n",
      "|       John|   Clothing|   600|2023-01-19|\n",
      "+-----------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(sales_df\n",
    " .where('amount > 500')\n",
    " .sort('amount', ascending=False).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e719317919d86e3",
   "metadata": {},
   "source": [
    "# Challenge 2: Window Functions (Intermediate)\n",
    "Problem: Analyze employee salary data using window functions.\n",
    "\n",
    "Expected Skills: Window functions, ranking, cumulative operations, lead/lag functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "267ef5a63b013138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:06:19.669795Z",
     "start_time": "2025-07-19T18:06:19.643646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Employee salary data\n",
    "emp_data = [\n",
    "    (1, \"Alice\", \"Engineering\", 75000, \"2020-01-01\"),\n",
    "    (2, \"Bob\", \"Engineering\", 80000, \"2019-06-15\"),\n",
    "    (3, \"Charlie\", \"Marketing\", 65000, \"2021-03-01\"),\n",
    "    (4, \"Diana\", \"Engineering\", 85000, \"2018-09-01\"),\n",
    "    (5, \"Eve\", \"Marketing\", 70000, \"2020-11-01\"),\n",
    "    (6, \"Frank\", \"Sales\", 60000, \"2022-01-01\"),\n",
    "    (7, \"Grace\", \"Sales\", 62000, \"2021-08-01\")\n",
    "]\n",
    "\n",
    "emp_schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"hire_date\", StringType(), True)\n",
    "])\n",
    "\n",
    "emp_df = spark.createDataFrame(emp_data, emp_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeaa8d10945b3d4",
   "metadata": {},
   "source": [
    "## Rank employees by salary within each department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ca0ee1b0b42df46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:16:48.198963Z",
     "start_time": "2025-07-19T18:16:48.176789Z"
    }
   },
   "outputs": [],
   "source": [
    "emp_rank_by_department_df = (emp_df\n",
    "                             .withColumn('rank',\n",
    "                                         F.rank().over(\n",
    "                                             Window.partitionBy('department').orderBy('salary'))\n",
    "                                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aede060a3695c1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:16:50.368019Z",
     "start_time": "2025-07-19T18:16:50.114453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+------+----------+----+\n",
      "|emp_id|   name| department|salary| hire_date|rank|\n",
      "+------+-------+-----------+------+----------+----+\n",
      "|     1|  Alice|Engineering| 75000|2020-01-01|   1|\n",
      "|     2|    Bob|Engineering| 80000|2019-06-15|   2|\n",
      "|     4|  Diana|Engineering| 85000|2018-09-01|   3|\n",
      "|     3|Charlie|  Marketing| 65000|2021-03-01|   1|\n",
      "|     5|    Eve|  Marketing| 70000|2020-11-01|   2|\n",
      "|     6|  Frank|      Sales| 60000|2022-01-01|   1|\n",
      "|     7|  Grace|      Sales| 62000|2021-08-01|   2|\n",
      "+------+-------+-----------+------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_rank_by_department_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b96b4320b8a45",
   "metadata": {},
   "source": [
    "## Calculate running total of salaries ordered by hire date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2456e4d02c372ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:12:53.470831Z",
     "start_time": "2025-07-19T18:12:53.449314Z"
    }
   },
   "outputs": [],
   "source": [
    "running_total_salaries_df = emp_df.withColumn('hire_date', F.col('hire_date').cast('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddda5add779d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_total_salaries_df.withColumn('running_total_salary', F.sum('salary').over(Window.orderBy('hire_date'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae8622285bd78c",
   "metadata": {},
   "source": [
    "## Find the salary difference between each employee and the highest-paid employee in their department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63e8709ae43c1849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:25:59.498527Z",
     "start_time": "2025-07-19T18:25:59.466344Z"
    }
   },
   "outputs": [],
   "source": [
    "salary_difference_in_department_df = (emp_rank_by_department_df\n",
    "                                      .withColumn('rank',\n",
    "                                                  F.rank().over(\n",
    "                                                      Window.partitionBy('department').orderBy(F.desc('salary')))\n",
    "                                                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c41c2f27362f9648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:31:35.661166Z",
     "start_time": "2025-07-19T18:31:35.638573Z"
    }
   },
   "outputs": [],
   "source": [
    "salary_diff_window = Window.partitionBy('department').orderBy(F.desc('salary'))\n",
    "salary_difference_in_department_df = salary_difference_in_department_df.withColumns({\n",
    "    'is_highest_of_department': F.col('rank') == 1,\n",
    "    'diff_preceding_salary': F.coalesce(\n",
    "        F.col('salary') - F.lag('salary').over(salary_diff_window),\n",
    "        F.lit(0)\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f803b2360ef424",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_difference_in_department_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626d4577b53a0e6",
   "metadata": {},
   "source": [
    "## Identify the 2nd highest salary in each department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c30bdcaf9787e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:32:52.937656Z",
     "start_time": "2025-07-19T18:32:52.917842Z"
    }
   },
   "outputs": [],
   "source": [
    "second_highest_in_department_df = salary_difference_in_department_df.withColumn('is_second_highest_of_dept',\n",
    "                                                                                F.col('rank') == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a17d683f81804",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_highest_in_department_df.where(F.col('is_second_highest_of_dept')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fba2cb1c6ca797",
   "metadata": {},
   "source": [
    "# Challenge 3: Complex Joins and Data Quality (Intermediate-Advanced)\n",
    "\n",
    "Problem: Join customer, order, and product data while handling data quality issues.\n",
    "\n",
    "Expected Skills: Multiple join types, data quality checks, null handling, data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fefe105db5488276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:36:43.743618Z",
     "start_time": "2025-07-19T18:36:43.686567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Customer data\n",
    "customers_data = [\n",
    "    (1, \"John Doe\", \"john@email.com\", \"New York\"),\n",
    "    (2, \"Jane Smith\", \"jane@email.com\", \"California\"),\n",
    "    (3, \"Bob Johnson\", None, \"Texas\"),  # Missing email\n",
    "    (4, \"Alice Brown\", \"alice@email.com\", \"Florida\")\n",
    "]\n",
    "\n",
    "# Orders data (some customers might not exist)\n",
    "orders_data = [\n",
    "    (101, 1, \"2023-01-15\", 250.0),\n",
    "    (102, 2, \"2023-01-16\", 180.0),\n",
    "    (103, 1, \"2023-01-17\", 320.0),\n",
    "    (104, 5, \"2023-01-18\", 150.0),  # Customer ID 5 doesn't exist\n",
    "    (105, 2, \"2023-01-19\", 200.0),\n",
    "    (106, 3, \"2023-01-20\", 175.0)\n",
    "]\n",
    "\n",
    "# Product orders (order line items)\n",
    "order_items_data = [\n",
    "    (101, \"P001\", 2, 125.0),\n",
    "    (102, \"P002\", 1, 180.0),\n",
    "    (103, \"P001\", 1, 125.0),\n",
    "    (103, \"P003\", 1, 195.0),\n",
    "    (105, \"P002\", 2, 100.0),\n",
    "    (106, \"P001\", 1, 125.0),\n",
    "    (106, \"P004\", 1, 50.0)\n",
    "]\n",
    "\n",
    "customers_df = spark.createDataFrame(customers_data,\n",
    "                                     [\"customer_id\", \"name\", \"email\", \"state\"])\n",
    "orders_df = spark.createDataFrame(orders_data,\n",
    "                                  [\"order_id\", \"customer_id\", \"order_date\", \"total_amount\"])\n",
    "order_items_df = spark.createDataFrame(order_items_data,\n",
    "                                       [\"order_id\", \"product_id\", \"quantity\", \"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d793cf47aefeadf",
   "metadata": {},
   "source": [
    "## Identify and handle orphaned orders (orders without valid customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fb87b9141116a97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T18:50:47.880558Z",
     "start_time": "2025-07-19T18:50:47.871476Z"
    }
   },
   "outputs": [],
   "source": [
    "customers_orders_df = customers_df.join(orders_df, how='full', on='customer_id')\n",
    "# joined_df = joined_df.join(order_items_df, how='full', on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85cf50a10c5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2a17ad7fee98400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:04:52.275277Z",
     "start_time": "2025-07-19T19:04:52.253701Z"
    }
   },
   "outputs": [],
   "source": [
    "order_without_customers_df = customers_orders_df.where(customers_df.customer_id.isNull()).withColumns({\n",
    "    'name': F.coalesce(F.col('name'), F.lit('Not registered')),\n",
    "    'email': F.coalesce(F.col('email'), F.lit('Not registered')),\n",
    "    'state': F.coalesce(F.col('state'), F.lit('Not registered'))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5efb97d3be2196f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:04:54.641663Z",
     "start_time": "2025-07-19T19:04:54.397625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+--------------+--------+----------+------------+\n",
      "|customer_id|          name|         email|         state|order_id|order_date|total_amount|\n",
      "+-----------+--------------+--------------+--------------+--------+----------+------------+\n",
      "|          5|Not registered|Not registered|Not registered|     104|2023-01-18|       150.0|\n",
      "+-----------+--------------+--------------+--------------+--------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_without_customers_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb110b851cd84f40",
   "metadata": {},
   "source": [
    "## Find customers with no orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ef07eb08daeaae5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:00:31.715023Z",
     "start_time": "2025-07-19T19:00:31.468004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+-------+\n",
      "|customer_id|       name|          email|  state|\n",
      "+-----------+-----------+---------------+-------+\n",
      "|          4|Alice Brown|alice@email.com|Florida|\n",
      "+-----------+-----------+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(customers_orders_df\n",
    " .where(F.col('order_id').isNull())\n",
    " .select(['customer_id', 'name', 'email', 'state'])\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691d2e5b16641b2",
   "metadata": {},
   "source": [
    "## Calculate total revenue by state, handling missing data appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48c49e51ff58e673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:06:04.466632Z",
     "start_time": "2025-07-19T19:06:04.435204Z"
    }
   },
   "outputs": [],
   "source": [
    "total_revenue_by_state_df = customers_orders_df.groupBy('state').agg(\n",
    "    F.coalesce(F.sum('total_amount').alias('total_amount'), F.lit(0))\n",
    ").withColumn('state', F.coalesce(F.col('state'), F.lit('Not registered')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6fc1d25b8842def0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:06:06.676866Z",
     "start_time": "2025-07-19T19:06:06.277882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------------------------+\n",
      "|         state|coalesce(sum(total_amount) AS total_amount, 0)|\n",
      "+--------------+----------------------------------------------+\n",
      "|         Texas|                                         175.0|\n",
      "|Not registered|                                         150.0|\n",
      "|       Florida|                                           0.0|\n",
      "|    California|                                         380.0|\n",
      "|      New York|                                         570.0|\n",
      "+--------------+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_revenue_by_state_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5bcc47ef15ddb",
   "metadata": {},
   "source": [
    "## Validate data consistency between orders and order_items tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b0315d258cb9e28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:07:12.830070Z",
     "start_time": "2025-07-19T19:07:12.803187Z"
    }
   },
   "outputs": [],
   "source": [
    "orders_items_df = orders_df.join(order_items_df, how=\"outer\", on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9acad5ca33851bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:07:18.783475Z",
     "start_time": "2025-07-19T19:07:18.457545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+------------+----------+--------+-----+\n",
      "|order_id|customer_id|order_date|total_amount|product_id|quantity|price|\n",
      "+--------+-----------+----------+------------+----------+--------+-----+\n",
      "|     101|          1|2023-01-15|       250.0|      P001|       2|125.0|\n",
      "|     102|          2|2023-01-16|       180.0|      P002|       1|180.0|\n",
      "|     103|          1|2023-01-17|       320.0|      P001|       1|125.0|\n",
      "|     103|          1|2023-01-17|       320.0|      P003|       1|195.0|\n",
      "|     104|          5|2023-01-18|       150.0|      NULL|    NULL| NULL|\n",
      "|     105|          2|2023-01-19|       200.0|      P002|       2|100.0|\n",
      "|     106|          3|2023-01-20|       175.0|      P001|       1|125.0|\n",
      "|     106|          3|2023-01-20|       175.0|      P004|       1| 50.0|\n",
      "+--------+-----------+----------+------------+----------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_items_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f408c92067e2161c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:22:35.185533Z",
     "start_time": "2025-07-19T19:22:35.130986Z"
    }
   },
   "outputs": [],
   "source": [
    "orders_items_grouped_df = orders_items_df.groupby('order_id', 'total_amount').agg(\n",
    "    F.sum('quantity').alias('total_items'),\n",
    "    F.sum(F.col('price') * F.col('quantity')).alias('total_amount_items')\n",
    ").orderBy('order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e893f1903fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_items_grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "550ac3b95c97d32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:25:02.183521Z",
     "start_time": "2025-07-19T19:25:02.163384Z"
    }
   },
   "outputs": [],
   "source": [
    "orders_items_check_df = orders_items_grouped_df.withColumns({\n",
    "    'values_match': F.coalesce(F.col('total_amount') == F.col('total_amount_items'), F.lit(False)),\n",
    "    'has_items': F.col('total_items').isNotNull()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80d25ba8086f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_items_check_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971325929943a61",
   "metadata": {},
   "source": [
    "# Challenge 4: Advanced Aggregations and Pivoting (Advanced)\n",
    "\n",
    "Problem: Analyze time-series sales data with complex aggregations.\n",
    "\n",
    "Expected Skills: Pivot operations, time-series analysis, complex window functions, OLAP operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d603e017bc591b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly sales data\n",
    "monthly_sales_data = [\n",
    "    (\"2023-01\", \"Electronics\", \"North\", 15000),\n",
    "    (\"2023-01\", \"Electronics\", \"South\", 12000),\n",
    "    (\"2023-01\", \"Clothing\", \"North\", 8000),\n",
    "    (\"2023-01\", \"Clothing\", \"South\", 6000),\n",
    "    (\"2023-02\", \"Electronics\", \"North\", 18000),\n",
    "    (\"2023-02\", \"Electronics\", \"South\", 14000),\n",
    "    (\"2023-02\", \"Clothing\", \"North\", 9000),\n",
    "    (\"2023-02\", \"Clothing\", \"South\", 7500),\n",
    "    (\"2023-03\", \"Electronics\", \"North\", 16000),\n",
    "    (\"2023-03\", \"Electronics\", \"South\", 13500),\n",
    "    (\"2023-03\", \"Clothing\", \"North\", 8500),\n",
    "    (\"2023-03\", \"Clothing\", \"South\", 7000)\n",
    "]\n",
    "\n",
    "monthly_sales_df = spark.createDataFrame(monthly_sales_data,\n",
    "                                         [\"month\", \"category\", \"region\", \"sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282e6c2",
   "metadata": {},
   "source": [
    "## Create a pivot table showing sales by month (rows) and region (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way it also works and gives flexibiity to apply more than one aggregation\n",
    "# pivot_month_and_region_df = monthly_sales_df.groupBy('month').pivot('region').agg(F.sum(\"sales\").alias(\"total_sales\"))\n",
    "\n",
    "pivot_month_and_region_df = monthly_sales_df.groupBy('month').pivot('region').sum(\"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b89a2d",
   "metadata": {},
   "source": [
    "## Calculate month-over-month growth rate for each category-region combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d77a66d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-------+-----+----------+---------------+\n",
      "|   category|region|  month|sales|mom_growth|mom_growth_rate|\n",
      "+-----------+------+-------+-----+----------+---------------+\n",
      "|   Clothing| North|2023-01| 8000|      NULL|           NULL|\n",
      "|   Clothing| North|2023-02| 9000|      1000|           12.5|\n",
      "|   Clothing| North|2023-03| 8500|      -500|          -5.56|\n",
      "|   Clothing| South|2023-01| 6000|      NULL|           NULL|\n",
      "|   Clothing| South|2023-02| 7500|      1500|           25.0|\n",
      "|   Clothing| South|2023-03| 7000|      -500|          -6.67|\n",
      "|Electronics| North|2023-01|15000|      NULL|           NULL|\n",
      "|Electronics| North|2023-02|18000|      3000|           20.0|\n",
      "|Electronics| North|2023-03|16000|     -2000|         -11.11|\n",
      "|Electronics| South|2023-01|12000|      NULL|           NULL|\n",
      "|Electronics| South|2023-02|14000|      2000|          16.67|\n",
      "|Electronics| South|2023-03|13500|      -500|          -3.57|\n",
      "+-----------+------+-------+-----+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate month-over-month growth rate for each category-region combination\n",
    "\n",
    "month_category_region_window = Window.partitionBy(\n",
    "    ['category', 'region']).orderBy('month')\n",
    "\n",
    "monthly_sales_df = monthly_sales_df.groupBy(['category', 'region', 'month']).agg(\n",
    "    F.sum('sales').alias('sales')\n",
    ") \\\n",
    "    .withColumns({\n",
    "        'mom_growth': F.col('sales') - F.lag(F.col('sales'), 1).over(month_category_region_window),\n",
    "        'mom_growth_rate': F.round((F.col('sales') / F.lag(F.col('sales'), 1).over(month_category_region_window) - 1) * 100, 2),\n",
    "    }) \\\n",
    "    .orderBy(['category', 'region', 'month'])\n",
    "\n",
    "monthly_sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0dfb1332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------------------+----------------+---------------------+------------------+----------------+---------------------+\n",
      "|   category|  month|North_first(sales)|North_mom_growth|North_mom_growth_rate|South_first(sales)|South_mom_growth|South_mom_growth_rate|\n",
      "+-----------+-------+------------------+----------------+---------------------+------------------+----------------+---------------------+\n",
      "|   Clothing|2023-01|              8000|            NULL|                 NULL|              6000|            NULL|                 NULL|\n",
      "|   Clothing|2023-02|              9000|            1000|                 12.5|              7500|            1500|                 25.0|\n",
      "|   Clothing|2023-03|              8500|            -500|                -5.56|              7000|            -500|                -6.67|\n",
      "|Electronics|2023-01|             15000|            NULL|                 NULL|             12000|            NULL|                 NULL|\n",
      "|Electronics|2023-02|             18000|            3000|                 20.0|             14000|            2000|                16.67|\n",
      "|Electronics|2023-03|             16000|           -2000|               -11.11|             13500|            -500|                -3.57|\n",
      "+-----------+-------+------------------+----------------+---------------------+------------------+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To make the result more concise it is possible to pivot\n",
    "# region into columns:\n",
    "\n",
    "monthly_sales_df.groupBy(['category', 'month']) \\\n",
    "    .pivot('region') \\\n",
    "    .agg(\n",
    "        F.first('sales'),\n",
    "        F.first('mom_growth').alias('mom_growth'),\n",
    "        F.first('mom_growth_rate').alias('mom_growth_rate')\n",
    "    ) \\\n",
    "    .orderBy(['category', 'month']) \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
