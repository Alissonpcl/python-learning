{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "e96d57d6b3ab0823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from cgi import print_environ_usage\n",
    "\n",
    "import pandas as pd\n",
    "import inspect"
   ],
   "id": "90c00007a1be481a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helpers",
   "id": "c8c19deb465475e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "help(zip)\n",
    "\n",
    "# Output\n",
    "# Help on class zip in module builtins:\n",
    "#\n",
    "# class zip(object)\n",
    "# |  zip(*iterables, strict=False) --> Yield tuples until an input is exhausted.\n",
    "# |\n",
    "# |     >>> list(zip('abcdefg', range(3), range(4)))\n",
    "# |     [('a', 0, 0), ('b', 1, 1), ('c', 2, 2)]\n",
    "# |\n",
    "# |  The zip object yields n-length tuples, where n is the number of iterables\n",
    "# |  passed as positional arguments to zip().  The i-th element in every tuple\n",
    "# |  comes from the i-th iterable argument to zip().  This continues until the\n",
    "# |  shortest argument is exhausted.\n",
    "# |"
   ],
   "id": "160c526da50356c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dir(zip)\n",
    "\n",
    "# Output\n",
    "# ['__class__',\n",
    "#  '__delattr__',\n",
    "#  '__dir__',\n",
    "#  '__doc__',\n",
    "#  '__eq__',\n",
    "#  '__format__',\n",
    "#  '__ge__',\n",
    "#   ....\n",
    "#  '__next__',\n",
    "#  '__setstate__',\n",
    "#  '__sizeof__',\n",
    "#  '__str__',\n",
    "#  '__subclasshook__']"
   ],
   "id": "e3cbfa668b79cade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inspect.signature(pd.read_csv)\n",
    "\n",
    "# Output\n",
    "# <Signature (filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols: 'UsecolsArgType' = None, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters: 'Mapping[Hashable, Callable] | None' = None, true_values: 'list | None' = None, false_values: 'list | None' = None, skipinitialspace: 'bool' = False, skiprows: 'list[int] | int | Callable[[Hashable], bool] | None' = None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values: 'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None' = None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool | lib.NoDefault' = <no_default>, skip_blank_lines: 'bool' = True, parse_dates: 'bool | Sequence[Hashable] | None' = None, infer_datetime_format: 'bool | lib.NoDefault' = <no_default>, keep_date_col: 'bool | lib.NoDefault' = <no_default>, date_parser: 'Callable | lib.NoDefault' = <no_default>, date_format: 'str | dict[Hashable, str] | None' = None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, on_bad_lines: 'str' = 'error', delim_whitespace: 'bool | lib.NoDefault' = <no_default>, low_memory: 'bool' = True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions | None' = None, dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>) -> 'DataFrame | TextFileReader'>"
   ],
   "id": "a9aecc8f53d607b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Iterators / Iterables",
   "id": "390356989d65c5d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T22:04:33.788114Z",
     "start_time": "2025-07-08T22:04:33.784328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterators are objects that can be iterated over. When you use `for i in x`, x is an iterator.\n",
    "# The code below is an example of a custom object that is an Iterator and an Iterable\n",
    "# Iterator = Object that returns and iterable (implement __iter__)\n",
    "# Iterable = Object that can be iterated (implement __next__)\n",
    "class MyIterator:\n",
    "    def __init__(self):\n",
    "        self.value = 'Alisson'\n",
    "        self.current = 0\n",
    "        self.max = len(self.value)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current < self.max:\n",
    "            curr_value = self.value[self.current]\n",
    "            self.current += 1\n",
    "            return curr_value\n",
    "\n",
    "        raise StopIteration\n",
    "\n",
    "\n",
    "iterator = MyIterator()\n",
    "\n",
    "for i in iterator:\n",
    "    print(i, end='')"
   ],
   "id": "2655918464e5f9c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alisson"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# File Handling",
   "id": "c1fcf59bdfccf482"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T21:45:03.375728Z",
     "start_time": "2025-07-08T21:45:03.373667Z"
    }
   },
   "cell_type": "code",
   "source": "file = open('data/people.json')",
   "id": "d59ee5cea8c92484",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T21:45:04.509780Z",
     "start_time": "2025-07-08T21:45:04.504441Z"
    }
   },
   "cell_type": "code",
   "source": "help(file)",
   "id": "ead120ba6204f26d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TextIOWrapper in module _io object:\n",
      "\n",
      "class TextIOWrapper(_TextIOBase)\n",
      " |  TextIOWrapper(buffer, encoding=None, errors=None, newline=None, line_buffering=False, write_through=False)\n",
      " |\n",
      " |  Character and line based layer over a BufferedIOBase object, buffer.\n",
      " |\n",
      " |  encoding gives the name of the encoding that the stream will be\n",
      " |  decoded or encoded with. It defaults to locale.getencoding().\n",
      " |\n",
      " |  errors determines the strictness of encoding and decoding (see\n",
      " |  help(codecs.Codec) or the documentation for codecs.register) and\n",
      " |  defaults to \"strict\".\n",
      " |\n",
      " |  newline controls how line endings are handled. It can be None, '',\n",
      " |  '\\n', '\\r', and '\\r\\n'.  It works as follows:\n",
      " |\n",
      " |  * On input, if newline is None, universal newlines mode is\n",
      " |    enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      " |    these are translated into '\\n' before being returned to the\n",
      " |    caller. If it is '', universal newline mode is enabled, but line\n",
      " |    endings are returned to the caller untranslated. If it has any of\n",
      " |    the other legal values, input lines are only terminated by the given\n",
      " |    string, and the line ending is returned to the caller untranslated.\n",
      " |\n",
      " |  * On output, if newline is None, any '\\n' characters written are\n",
      " |    translated to the system default line separator, os.linesep. If\n",
      " |    newline is '' or '\\n', no translation takes place. If newline is any\n",
      " |    of the other legal values, any '\\n' characters written are translated\n",
      " |    to the given string.\n",
      " |\n",
      " |  If line_buffering is True, a call to flush is implied when a call to\n",
      " |  write contains a newline character.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      TextIOWrapper\n",
      " |      _TextIOBase\n",
      " |      _IOBase\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |\n",
      " |  __reduce__(...)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __reduce_ex__(...)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  close(self, /)\n",
      " |      Flush and close the IO object.\n",
      " |\n",
      " |      This method has no effect if the file is already closed.\n",
      " |\n",
      " |  detach(self, /)\n",
      " |      Separate the underlying buffer from the TextIOBase and return it.\n",
      " |\n",
      " |      After the underlying buffer has been detached, the TextIO is in an unusable state.\n",
      " |\n",
      " |  fileno(self, /)\n",
      " |      Return underlying file descriptor if one exists.\n",
      " |\n",
      " |      Raise OSError if the IO object does not use a file descriptor.\n",
      " |\n",
      " |  flush(self, /)\n",
      " |      Flush write buffers, if applicable.\n",
      " |\n",
      " |      This is not implemented for read-only and non-blocking streams.\n",
      " |\n",
      " |  isatty(self, /)\n",
      " |      Return whether this is an 'interactive' stream.\n",
      " |\n",
      " |      Return False if it can't be determined.\n",
      " |\n",
      " |  read(self, size=-1, /)\n",
      " |      Read at most size characters from stream.\n",
      " |\n",
      " |      Read from underlying buffer until we have size characters or we hit EOF.\n",
      " |      If size is negative or omitted, read until EOF.\n",
      " |\n",
      " |  readable(self, /)\n",
      " |      Return whether object was opened for reading.\n",
      " |\n",
      " |      If False, read() will raise OSError.\n",
      " |\n",
      " |  readline(self, size=-1, /)\n",
      " |      Read until newline or EOF.\n",
      " |\n",
      " |      Return an empty string if EOF is hit immediately.\n",
      " |      If size is specified, at most size characters will be read.\n",
      " |\n",
      " |  reconfigure(self, /, *, encoding=None, errors=None, newline=None, line_buffering=None, write_through=None)\n",
      " |      Reconfigure the text stream with new parameters.\n",
      " |\n",
      " |      This also does an implicit stream flush.\n",
      " |\n",
      " |  seek(self, cookie, whence=0, /)\n",
      " |      Set the stream position, and return the new stream position.\n",
      " |\n",
      " |        cookie\n",
      " |          Zero or an opaque number returned by tell().\n",
      " |        whence\n",
      " |          The relative position to seek from.\n",
      " |\n",
      " |      Four operations are supported, given by the following argument\n",
      " |      combinations:\n",
      " |\n",
      " |      - seek(0, SEEK_SET): Rewind to the start of the stream.\n",
      " |      - seek(cookie, SEEK_SET): Restore a previous position;\n",
      " |        'cookie' must be a number returned by tell().\n",
      " |      - seek(0, SEEK_END): Fast-forward to the end of the stream.\n",
      " |      - seek(0, SEEK_CUR): Leave the current stream position unchanged.\n",
      " |\n",
      " |      Any other argument combinations are invalid,\n",
      " |      and may raise exceptions.\n",
      " |\n",
      " |  seekable(self, /)\n",
      " |      Return whether object supports random access.\n",
      " |\n",
      " |      If False, seek(), tell() and truncate() will raise OSError.\n",
      " |      This method may need to do a test seek().\n",
      " |\n",
      " |  tell(self, /)\n",
      " |      Return the stream position as an opaque number.\n",
      " |\n",
      " |      The return value of tell() can be given as input to seek(), to restore a\n",
      " |      previous stream position.\n",
      " |\n",
      " |  truncate(self, pos=None, /)\n",
      " |      Truncate file to size bytes.\n",
      " |\n",
      " |      File pointer is left unchanged. Size defaults to the current IO position\n",
      " |      as reported by tell(). Return the new size.\n",
      " |\n",
      " |  writable(self, /)\n",
      " |      Return whether object was opened for writing.\n",
      " |\n",
      " |      If False, write() will raise OSError.\n",
      " |\n",
      " |  write(self, text, /)\n",
      " |      Write string s to stream.\n",
      " |\n",
      " |      Return the number of characters written\n",
      " |      (which is always equal to the length of the string).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  buffer\n",
      " |\n",
      " |  closed\n",
      " |\n",
      " |  encoding\n",
      " |      Encoding of the text stream.\n",
      " |\n",
      " |      Subclasses should override.\n",
      " |\n",
      " |  errors\n",
      " |      The error setting of the decoder or encoder.\n",
      " |\n",
      " |      Subclasses should override.\n",
      " |\n",
      " |  line_buffering\n",
      " |\n",
      " |  name\n",
      " |\n",
      " |  newlines\n",
      " |      Line endings translated so far.\n",
      " |\n",
      " |      Only line endings translated during reading are considered.\n",
      " |\n",
      " |      Subclasses should override.\n",
      " |\n",
      " |  write_through\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _IOBase:\n",
      " |\n",
      " |  __del__(...)\n",
      " |\n",
      " |  __enter__(...)\n",
      " |\n",
      " |  __exit__(...)\n",
      " |\n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |\n",
      " |  readlines(self, hint=-1, /)\n",
      " |      Return a list of lines from the stream.\n",
      " |\n",
      " |      hint can be specified to control the number of lines read: no more\n",
      " |      lines will be read if the total size (in bytes/characters) of all\n",
      " |      lines so far exceeds hint.\n",
      " |\n",
      " |  writelines(self, lines, /)\n",
      " |      Write a list of lines to stream.\n",
      " |\n",
      " |      Line separators are not added, so it is usual for each of the\n",
      " |      lines provided to have a line separator at the end.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _IOBase:\n",
      " |\n",
      " |  __dict__\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load JSON file",
   "id": "e9fbb62e3eee6255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('data/people.json') as f:\n",
    "    data = json.load(f)"
   ],
   "id": "e5f9e4749dac0b4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data\n",
    "# [{'name': 'Alice', 'age': 28},\n",
    "#  {'name': 'Bob', 'age': 34},\n",
    "#  {'name': 'Charlie', 'age': 22},\n",
    "#  {'name': 'Diana', 'age': 31},\n",
    "#  {'name': 'Ethan', 'age': 45},\n",
    "#  {'name': 'Fiona', 'age': 27},\n",
    "#  {'name': 'George', 'age': 38},\n",
    "#  {'name': 'Hannah', 'age': 25},\n",
    "#  {'name': 'Ian', 'age': 29},\n",
    "#  {'name': 'Julia', 'age': 33}]"
   ],
   "id": "d3983d94b9d57c29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Very large CSV file",
   "id": "72860b003e6d7e94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T23:52:29.516603Z",
     "start_time": "2025-07-07T23:52:28.595444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def count_rows_above_threshold(filename, threshold=100):\n",
    "    counter = 0\n",
    "    with open(filename, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if float(row['amount']) > threshold:\n",
    "                counter += 1\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "def generate_test_csv(filename: str, num_rows=1000000):\n",
    "    print(f\"Generating {filename} with {num_rows:,} rows...\")\n",
    "\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write header\n",
    "        writer.writerow(['id', 'name', 'amount', 'category', 'date'])\n",
    "\n",
    "        # Generate random data\n",
    "        categories = ['Food', 'Entertainment', 'Shopping', 'Transportation', 'Utilities']\n",
    "\n",
    "        for i in range(1, num_rows + 1):\n",
    "            # Generate amounts with different distributions\n",
    "            if random.random() < 0.3:  # 30% chance of high amounts\n",
    "                amount = round(random.uniform(100, 1000), 2)\n",
    "            else:  # 70% chance of lower amounts\n",
    "                amount = round(random.uniform(1, 150), 2)\n",
    "\n",
    "            row = [\n",
    "                i,\n",
    "                f\"User_{i}\",\n",
    "                amount,\n",
    "                random.choice(categories),\n",
    "                f\"2025-07-{random.randint(1, 31):02d}\"\n",
    "            ]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Generated {filename} successfully!\")\n",
    "\n",
    "\n",
    "file_path = 'data/huge_csv.csv'\n",
    "size = 1000000\n",
    "\n",
    "# Must be uncommented to create to test file\n",
    "# generate_test_csv(file, size)\n",
    "\n",
    "print(\"\\nBenchmarking solutions:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nTesting {file_path} ({size:,} rows):\")\n",
    "\n",
    "# Test your implementation\n",
    "start_time = time.time()\n",
    "try:\n",
    "    result = count_rows_above_threshold(file_path)\n",
    "    end_time = time.time()\n",
    "    print(f\"  Your solution: {result} rows > 100 ({end_time - start_time:.4f}s)\")\n",
    "except Exception as e:\n",
    "    print(f\"  Your solution: Error - {e}\")"
   ],
   "id": "5e1e5ce84e1af4b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking solutions:\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing data/huge_csv.csv (1,000,000 rows):\n",
      "  Your solution: 534519 rows > 100 (0.9141s)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Date & Time\n",
    "\n",
    "| Format String | Meaning          | Example |\n",
    "| ------------- | ---------------- | ------- |\n",
    "| `%Y`          | Year (4 digits)  | `2025`  |\n",
    "| `%m`          | Month (2 digits) | `06`    |\n",
    "| `%d`          | Day              | `24`    |\n",
    "| `%H`          | Hour (24h)       | `19`    |\n",
    "| `%M`          | Minute           | `00`    |\n",
    "| `%S`          | Second           | `45`    |\n"
   ],
   "id": "88e2dd47f76ae17a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime, timedelta, date, UTC\n",
    "\n",
    "# Current local time\n",
    "now = datetime.now()\n",
    "now"
   ],
   "id": "f5ec663128578f59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Current UTC time\n",
    "utc_now = datetime.now(UTC)\n",
    "utc_now"
   ],
   "id": "b99d12b56f9e8587",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Current date only\n",
    "today = date.today()\n",
    "today"
   ],
   "id": "66b63190e236518e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## String <> Datetime Conversion",
   "id": "cd9a57637b4bfe30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T00:49:28.713328Z",
     "start_time": "2025-06-25T00:49:28.708641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt = datetime.strptime(\"2025-06-24 19:00\", \"%Y-%m-%d %H:%M\")\n",
    "dt\n",
    "\n",
    "# datetime.datetime(2025, 6, 24, 19, 0)"
   ],
   "id": "7959bf6c08f7fa61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 6, 24, 19, 0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T00:50:23.417333Z",
     "start_time": "2025-06-25T00:50:23.415293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s = dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "s\n",
    "\n",
    "# '2025-06-24 19:00'"
   ],
   "id": "283c9e74bd466241",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-06n-24 19:00'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add, subtract, time delta",
   "id": "19a5f643ed0ac9b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "yesterday = today - timedelta(days=1)\n",
    "tomorrow = today + timedelta(days=1)"
   ],
   "id": "c835e4306b12889f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T00:47:07.639574Z",
     "start_time": "2025-06-25T00:47:07.636137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "delta = timedelta(days=5, hours=0)\n",
    "new_time = now + delta\n",
    "new_time"
   ],
   "id": "847539d032b67720",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 6, 29, 21, 40, 54, 750434)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Structures\n",
    "\n",
    "| **Data Structure**              | **Properties**                                                                                             | **When to Use**                                                                                           |\n",
    "| ------------------------------- | ---------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |\n",
    "| **List** (`[]`)                 | - Ordered  <br> - Mutable  <br> - Allows duplicates  <br> - O(1) append <br> - O(n) search, insert, delete | - Ordered collection of items  <br> - Need to maintain sequence  <br> - Iteration and processing in order |\n",
    "| **Tuple** (`()`)                | - Ordered <br> - Immutable <br> - Allows duplicates <br> - Faster than list                                | - Fixed collection of items <br> - Keys in dictionaries <br> - Function return of multiple values         |\n",
    "| **Set** (`{}`)                  | - Unordered <br> - Unique elements <br> - No duplicates <br> - O(1) lookup and add                         | - Removing duplicates <br> - Membership tests <br> - Set operations (union, intersection)                 |\n",
    "| **Dict** (`{key: value}`)       | - Key-value pairs <br> - Unordered <br> - O(1) lookup by key <br> - Keys must be unique                    | - Fast lookups <br> - Mapping relationships (id → value) <br> - Counting, grouping                        |\n",
    "| **Deque** (`collections.deque`) | - Double-ended queue <br> - Fast append/pop both ends <br> - O(1) append/pop left and right                | - Queue or stack with fast performance <br> - Sliding windows, BFS                                        |\n",
    "| **Heap** (`heapq`)              | - Min-heap by default <br> - O(log n) insert and extract <br> - Always access smallest element             | - Priority queues <br> - Scheduling <br> - Top K elements                                                 |\n",
    "\n",
    "In plain words: <br/>\n",
    "✅ List → For general ordered sequences <br/>\n",
    "✅ Tuple → For fixed-size or immutable sequences <br/>\n",
    "✅ Set → For unique items & fast \"is this in?\" tests <br/>\n",
    "✅ Dict → For key-value mappings (extremely common in data engineering) <br/>\n",
    "✅ Deque → For efficient queue or stack <br/>\n",
    "✅ Heap → For \"always get me the smallest (or largest) item fast\"\n"
   ],
   "id": "7635498ed407bfb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lists",
   "id": "93a8070e54bb29bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create\n",
    "lst = [1, 2, 3]\n",
    "lst\n",
    "# [1, 2, 3]"
   ],
   "id": "67c0adbfb86c467",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add\n",
    "lst.append(4)\n",
    "lst\n",
    "# [1, 2, 3, 4]"
   ],
   "id": "68acef0c1e661c6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Insert\n",
    "lst.insert(1, 10)  # insert new item before index (index, new item)\n",
    "lst\n",
    "# [1, 10, 2, 3, 4]"
   ],
   "id": "e530c2f4ff57b2d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove\n",
    "lst.remove(4)  # remove the value; ValueError if not found\n",
    "lst"
   ],
   "id": "4e78e6592041cf9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lst.sort()  # doesn't work if the list has values from different types\n",
    "lst"
   ],
   "id": "4cf2c0d9c8cfa270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lst.reverse()  # sort descending\n",
    "lst"
   ],
   "id": "def1fba98574c683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# comprehension\n",
    "fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\n",
    "newlist = [x for x in fruits if \"a\" in x]\n",
    "newlist\n",
    "\n",
    "# ['apple', 'banana', 'mango']"
   ],
   "id": "8d148e33dba34668",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dicts",
   "id": "bb98aab25f6a96ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create\n",
    "d = {'a': 1, 'b': 2}\n",
    "d\n",
    "# {'a': 1, 'b': 2}"
   ],
   "id": "cd3b36369ebaf06c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add/Update\n",
    "d['c'] = 3\n",
    "d\n",
    "# {'a': 1, 'b': 2, 'c': 3}"
   ],
   "id": "94791659f2be928d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Access\n",
    "value = d.get('a', 0)  # or just d['a']\n",
    "value"
   ],
   "id": "771a2efe404f330",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate\n",
    "for k, v in d.items():\n",
    "    print(k, v)\n",
    "\n",
    "# a 1\n",
    "# b 2\n",
    "# c 3"
   ],
   "id": "326b34e8f37d9d48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comprehension to generator\n",
    "keys = (k for k, v in d.items())\n",
    "print(keys)\n",
    "for k in keys:\n",
    "    print(k)\n",
    "\n",
    "# <generator object <genexpr> at 0x106a04ee0>\n",
    "# a\n",
    "# b\n",
    "# c"
   ],
   "id": "82343e346ccb5711",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comprehension to list\n",
    "keys = [k for k, v in d.items()]\n",
    "print(keys)\n",
    "for k in keys:\n",
    "    print(k)\n",
    "\n",
    "# ['a', 'b', 'c']\n",
    "# a\n",
    "# b\n",
    "# c"
   ],
   "id": "950019049fe05628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dict comprehension\n",
    "squares = {x: x ** 2 for x in range(5)}\n",
    "squares"
   ],
   "id": "4174741d97545bef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sets",
   "id": "fcff2742faa6f4f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create\n",
    "s = {1, 2, 3}\n",
    "s\n",
    "\n",
    "# {1, 2, 3}"
   ],
   "id": "18b497965be96a1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add\n",
    "s.add(4)\n",
    "s\n",
    "\n",
    "# {1, 2, 3, 4}"
   ],
   "id": "1dbd6b846a594752",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove\n",
    "s.discard(2)  # doesn't throw error if not found\n",
    "s\n",
    "\n",
    "# {1, 3, 4}"
   ],
   "id": "3ba4d404b1fb345d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set operations\n",
    "a = {1, 2, 3}\n",
    "b = {3, 4, 5}\n",
    "union = a | b\n",
    "intersection = a & b\n",
    "difference = a - b\n",
    "\n",
    "print(union)  # {1, 2, 3, 4, 5}\n",
    "print(intersection)  # {3}\n",
    "print(difference)  # {1, 2}"
   ],
   "id": "bf24bca0ba614233",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuples\n",
    "\n"
   ],
   "id": "b317047f4a4d9bda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create\n",
    "t = (1, 2, 3)\n",
    "\n",
    "# Unpack\n",
    "a, b, c = t\n",
    "\n",
    "# Useful in dict keys and as function return\n",
    "# return (min_val, max_val)"
   ],
   "id": "8b83fe9bc8a76b20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# as dict keys\n",
    "salaries = {}\n",
    "salaries[('John', 'Smith')] = 10000.0\n",
    "salaries[('John', 'Parker')] = 99999.0\n",
    "salaries\n",
    "\n",
    "# {('John', 'Smith'): 10000.0, ('John', 'Parker'): 99999.0}"
   ],
   "id": "473c08faa5d23b38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for k, v in salaries.items():\n",
    "    print(k[0], k[1], v)\n",
    "\n",
    "# John Smith 10000.0\n",
    "# John Parker 99999.0"
   ],
   "id": "25733b3e254c5bf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Queue and Stack",
   "id": "cd1df7755a80f875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Stack (LIFO) The same as list\n",
    "stack = []\n",
    "stack.append(10)\n",
    "v = stack.pop()\n",
    "print(v)  # 10\n",
    "print(stack)  # []"
   ],
   "id": "8664e24e64d5266e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "# Queue (FIFO)\n",
    "queue = deque()\n",
    "queue.append(10)\n",
    "queue.append(20)\n",
    "queue.append(30)\n",
    "queue\n",
    "\n",
    "# deque([10, 20, 30])"
   ],
   "id": "162a92d02f358c2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "queue.popleft()  # 10\n",
    "queue\n",
    "\n",
    "# deque([20, 30])"
   ],
   "id": "647bc0999f49fa39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "queue.pop()  # 30\n",
    "\n",
    "# deque([20])"
   ],
   "id": "f7ef66689d4233c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Transformations",
   "id": "e197575bc8e236f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filtering",
   "id": "88e289eb08f6b73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "young = [x for x in data if x['age'] < 40]\n",
    "young\n",
    "\n",
    "#  [{'name': 'Alice', 'age': 28},\n",
    "#  {'name': 'Charlie', 'age': 22},\n",
    "#  {'name': 'Fiona', 'age': 27},\n",
    "#  {'name': 'Hannah', 'age': 25},\n",
    "#  {'name': 'Ian', 'age': 29}]"
   ],
   "id": "83aba46b76e6dec7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sorting",
   "id": "bb05d43fe5ae8777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "young_sorted = sorted(young, key=lambda x: x['age'])\n",
    "young_sorted\n",
    "\n",
    "# [{'name': 'Charlie', 'age': 22},\n",
    "#  {'name': 'Hannah', 'age': 25},\n",
    "#  {'name': 'Fiona', 'age': 27},\n",
    "#  {'name': 'Alice', 'age': 28},\n",
    "#  {'name': 'Ian', 'age': 29},\n",
    "#  {'name': 'Diana', 'age': 31},\n",
    "#  {'name': 'Julia', 'age': 33},\n",
    "#  {'name': 'Bob', 'age': 34},\n",
    "#  {'name': 'George', 'age': 38}]"
   ],
   "id": "b574faa6d830e50d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grouping",
   "id": "76878c07118e93ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T23:26:37.088417Z",
     "start_time": "2025-07-07T23:26:37.081200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_user_totals(purchase_records):\n",
    "    total_by_user = {}\n",
    "    for purchase in purchase_records:\n",
    "        user_id = purchase['user_id']\n",
    "        amount = purchase['amount']\n",
    "\n",
    "        if user_id in total_by_user:\n",
    "            total_by_user[user_id] += amount\n",
    "        else:\n",
    "            total_by_user[user_id] = amount\n",
    "\n",
    "    return total_by_user\n",
    "\n",
    "\n",
    "test_data = [\n",
    "    {\"user_id\": 42, \"amount\": 199.90},\n",
    "    {\"user_id\": 15, \"amount\": 75.50},\n",
    "    {\"user_id\": 42, \"amount\": 99.90},\n",
    "    {\"user_id\": 88, \"amount\": 250.00},\n",
    "    {\"user_id\": 15, \"amount\": 74.50},\n",
    "    {\"user_id\": 42, \"amount\": 25.00},\n",
    "    {\"user_id\": 99, \"amount\": 300.75},\n",
    "    {\"user_id\": 88, \"amount\": 89.99},\n",
    "    {\"user_id\": 15, \"amount\": 120.00}\n",
    "]\n",
    "\n",
    "result = calculate_user_totals(test_data)\n",
    "print(\"Your result:\", result)\n",
    "\n",
    "# Additional test cases\n",
    "print(\"\\nTesting edge cases:\")\n",
    "\n",
    "# Empty list\n",
    "empty_result = calculate_user_totals([])\n",
    "print(\"Empty list result:\", empty_result)\n",
    "\n",
    "# Single record\n",
    "single_record = [{\"user_id\": 1, \"amount\": 100.0}]\n",
    "single_result = calculate_user_totals(single_record)\n",
    "print(\"Single record result:\", single_result)\n",
    "\n",
    "# Duplicate user_id with same amount\n",
    "duplicate_test = [\n",
    "    {\"user_id\": 10, \"amount\": 50.0},\n",
    "    {\"user_id\": 10, \"amount\": 50.0}\n",
    "]\n",
    "duplicate_result = calculate_user_totals(duplicate_test)\n",
    "print(\"Duplicate test result:\", duplicate_result)"
   ],
   "id": "2e7d1f940eaf40ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your result: {42: 324.8, 15: 270.0, 88: 339.99, 99: 300.75}\n",
      "\n",
      "Testing edge cases:\n",
      "Empty list result: {}\n",
      "Single record result: {1: 100.0}\n",
      "Duplicate test result: {10: 100.0}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Counting",
   "id": "7f1b5d1ddef74020"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T23:34:13.787416Z",
     "start_time": "2025-07-07T23:34:13.782914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def count_event_types(logs):\n",
    "#     logs_by_type_count = {}\n",
    "#     for log in logs:\n",
    "#         event = log['event'].lower()\n",
    "#         if event in logs_by_type_count:\n",
    "#             logs_by_type_count[event] += 1\n",
    "#         else:\n",
    "#             logs_by_type_count[event] = 1\n",
    "#\n",
    "#     return logs_by_type_count\n",
    "\n",
    "# Most Pythonic version\n",
    "def count_event_types(logs):\n",
    "    from collections import Counter\n",
    "    return Counter(log['event'].lower() for log in logs)\n",
    "\n",
    "\n",
    "# Test data to practice with\n",
    "test_logs = [\n",
    "    {\"timestamp\": \"2025-07-05T10:00:00Z\", \"event\": \"click\", \"user_id\": 1},\n",
    "    {\"timestamp\": \"2025-07-05T10:05:00Z\", \"event\": \"purchase\", \"user_id\": 1},\n",
    "    {\"timestamp\": \"2025-07-05T10:10:00Z\", \"event\": \"view\", \"user_id\": 2},\n",
    "    {\"timestamp\": \"2025-07-05T10:15:00Z\", \"event\": \"click\", \"user_id\": 2},\n",
    "    {\"timestamp\": \"2025-07-05T10:20:00Z\", \"event\": \"click\", \"user_id\": 3},\n",
    "    {\"timestamp\": \"2025-07-05T10:25:00Z\", \"event\": \"view\", \"user_id\": 1},\n",
    "    {\"timestamp\": \"2025-07-05T10:30:00Z\", \"event\": \"purchase\", \"user_id\": 3},\n",
    "    {\"timestamp\": \"2025-07-05T10:35:00Z\", \"event\": \"view\", \"user_id\": 4},\n",
    "    {\"timestamp\": \"2025-07-05T10:40:00Z\", \"event\": \"click\", \"user_id\": 4},\n",
    "    {\"timestamp\": \"2025-07-05T10:45:00Z\", \"event\": \"logout\", \"user_id\": 2},\n",
    "    {\"timestamp\": \"2025-07-05T10:50:00Z\", \"event\": \"login\", \"user_id\": 5},\n",
    "    {\"timestamp\": \"2025-07-05T10:55:00Z\", \"event\": \"view\", \"user_id\": 5}\n",
    "]\n",
    "\n",
    "# Expected result for test_logs:\n",
    "# {\"click\": 4, \"purchase\": 2, \"view\": 4, \"logout\": 1, \"login\": 1}\n",
    "\n",
    "# Test your function\n",
    "if __name__ == \"__main__\":\n",
    "    result = count_event_types(test_logs)\n",
    "    print(\"Your result:\", result)\n",
    "\n",
    "    # Additional test cases\n",
    "    print(\"\\nTesting edge cases:\")\n",
    "\n",
    "    # Empty list\n",
    "    empty_result = count_event_types([])\n",
    "    print(\"Empty list result:\", empty_result)\n",
    "\n",
    "    # Single event type\n",
    "    single_event = [\n",
    "        {\"timestamp\": \"2025-07-05T10:00:00Z\", \"event\": \"click\", \"user_id\": 1},\n",
    "        {\"timestamp\": \"2025-07-05T10:05:00Z\", \"event\": \"click\", \"user_id\": 2}\n",
    "    ]\n",
    "    single_result = count_event_types(single_event)\n",
    "    print(\"Single event type result:\", single_result)\n",
    "\n",
    "    # All different event types\n",
    "    different_events = [\n",
    "        {\"timestamp\": \"2025-07-05T10:00:00Z\", \"event\": \"signup\", \"user_id\": 1},\n",
    "        {\"timestamp\": \"2025-07-05T10:05:00Z\", \"event\": \"activation\", \"user_id\": 2},\n",
    "        {\"timestamp\": \"2025-07-05T10:10:00Z\", \"event\": \"conversion\", \"user_id\": 3}\n",
    "    ]\n",
    "    different_result = count_event_types(different_events)\n",
    "    print(\"All different events result:\", different_result)\n",
    "\n",
    "    # Case sensitivity test\n",
    "    case_test = [\n",
    "        {\"timestamp\": \"2025-07-05T10:00:00Z\", \"event\": \"Click\", \"user_id\": 1},\n",
    "        {\"timestamp\": \"2025-07-05T10:05:00Z\", \"event\": \"CLICK\", \"user_id\": 2},\n",
    "        {\"timestamp\": \"2025-07-05T10:10:00Z\", \"event\": \"click\", \"user_id\": 3}\n",
    "    ]\n",
    "    case_result = count_event_types(case_test)\n",
    "    print(\"Case sensitivity test result:\", case_result)"
   ],
   "id": "221158654a01255b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your result: Counter({'click': 4, 'view': 4, 'purchase': 2, 'logout': 1, 'login': 1})\n",
      "click 4\n",
      "purchase 2\n",
      "view 4\n",
      "logout 1\n",
      "login 1\n",
      "\n",
      "Testing edge cases:\n",
      "Empty list result: Counter()\n",
      "Single event type result: Counter({'click': 2})\n",
      "All different events result: Counter({'signup': 1, 'activation': 1, 'conversion': 1})\n",
      "Case sensitivity test result: Counter({'click': 3})\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
