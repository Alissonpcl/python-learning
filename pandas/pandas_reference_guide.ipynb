{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import",
   "id": "7bc47e0e3fdd96e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from os import rename\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataframes",
   "id": "b87c48b83c1b4252"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## from dict",
   "id": "f96e112ecff716dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = {\n",
    "    'Country': ['Belgium', 'India', 'Brazil'],\n",
    "    'Capital': ['Brussels', 'New Delhi', 'Brasilia'],\n",
    "    'Population': [100, 200, 300]\n",
    "}\n",
    "df = pd.DataFrame(data, columns=['Country', 'Capital', 'Population'])"
   ],
   "id": "2ab6cc12e8c66d12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## from files",
   "id": "57a7d60bee4c2e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CSV",
   "id": "d3fab87b1eb8abfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Simple read file\n",
    "df = pd.read_csv(\"../data/products.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Most commons params\n",
    "\n",
    "| Parameter                   | Description                                                | Common Use Case                                             |\n",
    "| --------------------------- | ---------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| filepath_or_buffer          | File path (string or URL) or file-like object              | Required to point to the CSV file                           |\n",
    "| sep                         | Field delimiter (default is `','`)                         | Use `\\t` for TSV, `;` for European-style CSV                |\n",
    "| header                      | Row number to use as column names (default is `0`)         | Use `None` if there's no header                             |\n",
    "| names                       | List of column names to use (overrides `header`)           | Useful when header is missing or needs renaming             |\n",
    "| index_col                   | Column(s) to set as index                                  | Often used to set time or ID columns as index               |\n",
    "| usecols                     | Subset of columns to read (by name or index)               | Improves performance when not all columns are needed        |\n",
    "| dtype                       | Dict of column types                                       | Enforces type consistency or memory optimization            |\n",
    "| parse_dates                 | List of columns to parse as datetime                       | Automatically converts date strings into `datetime` objects |\n",
    "| infer_datetime_format       | Speed up datetime parsing when format is consistent        | Faster parsing with consistent formats                      |\n",
    "| na_values                   | List of strings to recognize as NaN                        | Customize missing value handling (`[\"NA\", \"NULL\", \"n/a\"]`)  |\n",
    "| skiprows                    | Number of lines to skip at the start                       | Useful for skipping metadata or junk rows                   |\n",
    "| nrows                       | Number of rows to read                                     | Used for sampling large files                               |\n",
    "| chunksize                   | Return an iterator with chunks of data (number of lines)   | Enables streaming large datasets in pieces                  |\n",
    "| encoding                    | Encoding of the file (default is `'utf-8'`)                | Use `'ISO-8859-1'` or `'latin1'` for special characters     |\n",
    "| compression                 | For compressed files (`'gzip'`, `'zip'`, etc.)             | Automatically handles zipped data files                     |\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ],
   "id": "c9ef10022e9dfafe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    This would read a CSV in chunks from S3,\n",
    "    parse timestamps,\n",
    "    optimize memory by enforcing types,\n",
    "    and limit to specific useful columns.\n",
    "\"\"\"\n",
    "df = pd.read_csv(\n",
    "    \"s3://bucket/data.csv\",\n",
    "    sep=\",\",\n",
    "    usecols=[\"id\", \"timestamp\", \"event_type\"],\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    dtype={\"id\": \"int32\", \"event_type\": \"category\"},\n",
    "    chunksize=100000\n",
    ")"
   ],
   "id": "6b9abcfdd8afb6b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    Treating date fields\n",
    "\"\"\"\n",
    "df = pd.read_csv(f\"{Path().absolute()}/netflix_titles.csv\",\n",
    "                 parse_dates=['date_added'],\n",
    "                 date_format='%B %d, %Y')\n",
    "\n",
    "# It's required to use str.strip() because some of the values\n",
    "# have a whitespace at the beginning\n",
    "df['date_added'] = pd.to_datetime(df['date_added'].str.strip(), format='%B %d, %Y')\n",
    "\n",
    "df.dtypes"
   ],
   "id": "5876e2312d660b60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## from database",
   "id": "62d8708b75d9e5c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection settings\n",
    "host = \"your_host\"\n",
    "port = \"5432\"\n",
    "database = \"your_database\"\n",
    "user = \"your_username\"\n",
    "password = \"your_password\"\n",
    "\n",
    "# Create the SQLAlchemy connection string\n",
    "connection_string = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"\n",
    "        SELECT id, name, created_at\n",
    "        FROM your_table\n",
    "        WHERE created_at >= CURRENT_DATE - INTERVAL '30 days' \\\n",
    "        \"\"\"\n",
    "\n",
    "# Read the query into a DataFrame\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Preview data\n",
    "print(df.head())\n"
   ],
   "id": "9c2bd456a0322ea7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## basic info",
   "id": "ea800db43e9bfc67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df.shape   # (rows,columns)\n",
    "# df.index   # Describe index\n",
    "# df.columns # Describe columns\n",
    "# df.info()  # Info of df\n",
    "df.count()  # Number of non-NA values"
   ],
   "id": "f63de1aeeb066378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving dataframes",
   "id": "4c018e591d7046a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## to files",
   "id": "7a95feb9849779a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.to_csv('data.csv', index=False)\n",
    "\n",
    "\"\"\"\n",
    "| Parameter             | Description                                           | Common Use Case                                         |\n",
    "| --------------------- | ----------------------------------------------------- | ------------------------------------------------------- |\n",
    "| path_or_buf           | File path or file-like object                         | Local path or cloud storage path                        |\n",
    "| sep                   | Field delimiter (default is `','`)                    | Use `\\t` for TSV or `;` in European formats             |\n",
    "| index                 | Whether to write row indices (default `True`)         | Set to `False` to exclude index column                  |\n",
    "| columns               | List of columns to write                              | Export only selected columns                            |\n",
    "| header                | Whether to write column names (default `True`)        | Set to `False` to exclude header row                    |\n",
    "| mode                  | Write mode (`'w'` or `'a'`)                           | `'a'` allows appending to existing files                |\n",
    "| encoding              | Output encoding (default `'utf-8'`)                   | Use `'utf-8-sig'` for Excel compatibility or `'latin1'` |\n",
    "| compression           | Compression format (`'gzip'`, `'zip'`, `'bz2'`, etc.) | Compress files during export                            |\n",
    "| line_terminator       | End-of-line character (`'\\n'`, `'\\r\\n'`)              | Control line endings across platforms                   |\n",
    "| float_format          | Format for floating-point numbers                     | Useful for consistent rounding (e.g., `\"%.2f\"`)         |\n",
    "| date_format           | Format for datetime columns                           | Standardize timestamp export (`\"%Y-%m-%d\"`)             |\n",
    "| quoting               | CSV quoting behavior (from `csv` module)              | Handle special characters in text                       |\n",
    "| chunksize             | Number of rows to write at a time                     | Useful for large data export                            |\n",
    "| na_rep                | Representation for NaN/missing values                 | Replace NaN with specific text (e.g., `'-'`)            |\n",
    "\n",
    "\"\"\""
   ],
   "id": "945bfd1b4db1dfc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tranformations",
   "id": "25c9ac36b996ebb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## drop columns",
   "id": "2414482c7ed549d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df2 = df.drop(columns=['Capital'])\n",
    "df2"
   ],
   "id": "57580c111ba65ab9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## drop rows",
   "id": "e5ec9bc043488477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df2 = df.drop(0)  # index-based, drops first row\n",
    "df2"
   ],
   "id": "3a3e03580d74b038",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## applying functions",
   "id": "a8e9db4412b6eefe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "f = lambda x: x * 3\n",
    "df2 = df.apply(f)"
   ],
   "id": "df047cac8f702949",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def concat_country_capital(row):\n",
    "    return f\"{row['Country']} ({row['Capital']})\"\n",
    "\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "# Using axis = 1, so the parameters passed to the function\n",
    "# is a PD Series representing the row\n",
    "df2['new_column'] = df2.apply(concat_country_capital, axis=1)\n",
    "df2"
   ],
   "id": "4e3893dddc05258d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Combining Data",
   "id": "60b4c79e9bc6a34d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## df merge",
   "id": "9da93cac64dda073"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# reading two csv files\n",
    "products_df = pd.read_csv(\"../data/products.csv\")\n",
    "sales_df = pd.read_csv(\"../data/sales.csv\", parse_dates=[\"sale_date\"])\n",
    "\n",
    "merged_sales_df = pd.merge(products_df, sales_df,\n",
    "                           on='product_id',\n",
    "                           how='left')\n",
    "\n",
    "merged_sales_df"
   ],
   "id": "6011f95bb84eda82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## finding absent values",
   "id": "9a8ccd727262252a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the CSV files\n",
    "products_df = pd.read_csv(\"../data/products.csv\")\n",
    "sales_df = pd.read_csv(\"../data/sales.csv\")\n",
    "\n",
    "# Find products without sales\n",
    "products_with_sales = sales_df[\"product_id\"].unique()\n",
    "\n",
    "# What doest the trick if the ~ operator, it works like \"not in\"\n",
    "products_without_sales = products_df[~products_df[\"product_id\"].isin(products_with_sales)]\n",
    "\n",
    "print(\"Products without sales:\")\n",
    "print(products_without_sales)"
   ],
   "id": "84df91e23ab898e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculations",
   "id": "4e52e432f4d352ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sort by index",
   "id": "e933b20555fed04a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df2 = df.sort_index(ascending=True)",
   "id": "e3626876cf7d1577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sort by values",
   "id": "e75bff8220bcdec2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df2 = df.sort_values(by='Capital', ascending=True)",
   "id": "693e46187f251475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## cumulative sum",
   "id": "4b07ba0e720eebec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "df2['Cumulative_pop'] = df2['Population'].cumsum()"
   ],
   "id": "ae1c36614815f8d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## min, max, mean, median, describe stats",
   "id": "c2ca30d72c13425b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df['Population'].min()\n",
    "# df['Population'].max()\n",
    "# df['Population'].mean() # = average\n",
    "# df['Population'].median() # middle value in a sorted dataset\n",
    "# df['Population'].describe()"
   ],
   "id": "4475949cf4bcac38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## group by and sum",
   "id": "bfc61ad451afd1e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sales_summary = (merged_sales_df.groupby('product_id')['quantity'].sum()\n",
    "                 .sort_values(ascending=False)\n",
    "                 .reset_index())\n",
    "sales_summary"
   ],
   "id": "5f7bb047aa611d0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## finding the highest sale (group, agg)",
   "id": "a72101b164932c1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group sales by product_id and sum the quantity\n",
    "# Calculate total revenue per product\n",
    "sales_summary = (\n",
    "    merged_sales_df\n",
    "    .groupby([\"product_id\", \"product_name\", \"category\", \"price\"])\n",
    "    .agg(total_quantity=(\"quantity\", \"sum\"),\n",
    "         total_revenue=(\"quantity\", lambda x: (x * merged_sales_df.loc[x.index, \"price\"]).sum()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort by quantity to find the most sold product\n",
    "most_sold_product = sales_summary.sort_values(by=\"total_revenue\", ascending=False).head(1)\n",
    "\n",
    "print(\"Most sold product with total revenue:\")\n",
    "print(most_sold_product)"
   ],
   "id": "f7b9c7fad797f45d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
